@MISC{vaswani2023attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cchen2021evaluatings.CL}
}


@article{GOTTFREDSON1997,
    author = {Linda S. Gottfredson},
    title = {Mainstream science on intelligence: An editorial with 52 signatories, history, and bibliography},
    journal = {Intelligence},
    volume = {24},
    number = {1},
    pages = {13-23},
    year = {1997},
    note = {Special Issue Intelligence and Social Policy},
    issn = {0160-2896},
    doi = {https://doi.org/10.1016/S0160-2896(97)90011-8},
    url = {https://www.sciencedirect.com/science/article/pii/S0160289697900118}
}


@misc{KSSJ:inteligencia,
    key = inteligencia,
    note = "inteligencia: Krátky slovník slovenského jazyka"
}

@misc{Gavrilova2020,
    title= {A Guide to Deep Learning and Neural Networks}, 
    author= {Yulia Gavrilova},
    month = 10,
    year={2020},
    url = {https://serokell.io/blog/deep-learning-and-neural-network-guide},
    publisher={serokell.io},
    howpublished={online},
}

@book{Novak1998,
    author =       "Mirko Novák and others",
    title =        "Umělé neuronové sítě. Teorie a aplikace.",
    publisher =    "C.\,H.\,BECK",
    edition =      "1",
    year =         "1998",
    address =      "Praha",
    isbn =         "80-7179-132-6",
}

@book{BishopDeepLearning,
    author =       "Christopher M.Bishop and Hugh Bishop",
    title =        "Deep learning : foundations and concepts",
    publisher =    "Springer",
    year =         "2024",
    address =      "Cham",
    isbn =         "978-3-031-45467-7",
    edition= "",
    doi="10.1007/978-3-031-45468-4",
    url="https://doi.org/10.1007/978-3-031-45468-4"
}

@article{McCulloch1990,
    author = {Warren S. McCulloch and Walter Pitts},
    title = {A logical calculus of the ideas immanent in nervous activity},
    journal = {Bulletin of Mathematical Biology},
    volume = {52},
    number = {1},
    pages = {99-115},
    year = {1990},
    issn = {0092-8240},
    doi = {https://doi.org/10.1016/S0092-8240(05)80006-0},
}

@misc{wiki:neuron,
    author = "Wikipédia",
    title = "Neurón --- Wikipédia{,} Slobodná encyklopédia",
    year = "2022",
    url = "https://sk.wikipedia.org/w/index.php?title=Neur%C3%B3n&oldid=7345982",
    note = "[Online; prístup 4-február-2024]"
}

@inproceedings{vig-2019-multiscale,
    title = "A Multiscale Visualization of Attention in the Transformer Model",
    author = "Vig, Jesse",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-3007",
    doi = "10.18653/v1/P19-3007",
    pages = "37--42",
}

@misc{llama2:prompt-format,
    title = "Llama 2 is here - get it on Hugging Face",
    url = "https://huggingface.co/blog/llama2#how-to-prompt-llama-2",
    note = "[Online; prístup 23-február-2024]"
 }

@article{TURING1950,
    author = {TURING, A. M.},
    title = {I.-COMPUTING MACHINERY AND INTELLIGENCE},
    journal = {Mind},
    volume = {LIX},
    number = {236},
    pages = {433-460},
    year = {1950},
    month = {10},
    issn = {0026-4423},
    doi = {10.1093/mind/LIX.236.433},
    url = {https://doi.org/10.1093/mind/LIX.236.433}
}

@article{LSTM1997,
    author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
    title = {Long Short-Term Memory},
    year = {1997},
    issue_date = {November 15, 1997},
    publisher = {MIT Press},
    address = {Cambridge, MA, USA},
    volume = {9},
    number = {8},
    edition={},
    issn = {0899-7667},
    url = {https://doi.org/10.1162/neco.1997.9.8.1735},
    doi = {10.1162/neco.1997.9.8.1735},
    journal = {Neural Comput.},
    month = {nov},
    pages = {1735–1780},
    numpages = {46}
}

@misc{hu2021lora,
    title={LoRA: Low-Rank Adaptation of Large Language Models}, 
    author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
    year={2021},
    eprint={2106.09685},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://doi.org/10.48550/arXiv.2106.09685},
    doi={10.48550/arXiv.2106.09685}
}

@misc{rokh2022modelquantization,
    title={A Comprehensive Survey on Model Quantization for Deep Neural Networks in Image Classification}, 
    author={Babak Rokh and Ali Azarpeyvand and Alireza Khanteymoori},
    year={2022},
    eprint={2205.07877},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://doi.org/10.1145/3623402},
    doi={10.1145/3623402}
}


@misc{liu2024understanding,
    title={Understanding LLMs: A Comprehensive Overview from Training to Inference}, 
    author={Yiheng Liu and Hao He and Tianle Han and Xu Zhang and Mengyuan Liu and Jiaming Tian and Yutong Zhang and Jiaqi Wang and Xiaohui Gao and Tianyang Zhong and Yi Pan and Shaochen Xu and Zihao Wu and Zhengliang Liu and Xin Zhang and Shu Zhang and Xintao Hu and Tuo Zhang and Ning Qiang and Tianming Liu and Bao Ge},
    year={2024},
    eprint={2401.02038},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    doi = {https://doi.org/10.48550/arXiv.2401.02038}
}

%% Fill in the Middle paper
@misc{bavarian2022efficient,
    title={Efficient Training of Language Models to Fill in the Middle}, 
    author={Mohammad Bavarian and Heewoo Jun and Nikolas Tezak and John Schulman and Christine McLeavey and Jerry Tworek and Mark Chen},
    year={2022},
    eprint={2207.14255},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    doi = {https://doi.org/10.48550/arXiv.2207.14255}
}

%% GPT-3 paper
@misc{brown2020language,
    title={Language Models are Few-Shot Learners}, 
    author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
    year={2020},
    eprint={2005.14165},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://doi.org/10.48550/arXiv.2005.14165},
    doi={10.48550/arXiv.2005.14165}
}

% GPT-Codex
@misc{chen2021evaluating,
    title={Evaluating Large Language Models Trained on Code}, 
    author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
    year={2021},
    eprint={2107.03374},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://doi.org/10.48550/arXiv.2107.03374},
    doi={10.48550/arXiv.2107.03374}
}

%% PaLM paper
@misc{chowdhery2022palm,
      title={PaLM: Scaling Language Modeling with Pathways}, 
      author={Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and Parker Schuh and Kensen Shi and Sasha Tsvyashchenko and Joshua Maynez and Abhishek Rao and Parker Barnes and Yi Tay and Noam Shazeer and Vinodkumar Prabhakaran and Emily Reif and Nan Du and Ben Hutchinson and Reiner Pope and James Bradbury and Jacob Austin and Michael Isard and Guy Gur-Ari and Pengcheng Yin and Toju Duke and Anselm Levskaya and Sanjay Ghemawat and Sunipa Dev and Henryk Michalewski and Xavier Garcia and Vedant Misra and Kevin Robinson and Liam Fedus and Denny Zhou and Daphne Ippolito and David Luan and Hyeontaek Lim and Barret Zoph and Alexander Spiridonov and Ryan Sepassi and David Dohan and Shivani Agrawal and Mark Omernick and Andrew M. Dai and Thanumalayan Sankaranarayana Pillai and Marie Pellat and Aitor Lewkowycz and Erica Moreira and Rewon Child and Oleksandr Polozov and Katherine Lee and Zongwei Zhou and Xuezhi Wang and Brennan Saeta and Mark Diaz and Orhan Firat and Michele Catasta and Jason Wei and Kathy Meier-Hellstern and Douglas Eck and Jeff Dean and Slav Petrov and Noah Fiedel},
      year={2022},
      eprint={2204.02311},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

%% CodeLlama paper
@misc{roziere2024code,
    title={Code Llama: Open Foundation Models for Code}, 
    author={Baptiste Rozière and Jonas Gehring and Fabian Gloeckle and Sten Sootla and Itai Gat and Xiaoqing Ellen Tan and Yossi Adi and Jingyu Liu and Romain Sauvestre and Tal Remez and Jérémy Rapin and Artyom Kozhevnikov and Ivan Evtimov and Joanna Bitton and Manish Bhatt and Cristian Canton Ferrer and Aaron Grattafiori and Wenhan Xiong and Alexandre Défossez and Jade Copet and Faisal Azhar and Hugo Touvron and Louis Martin and Nicolas Usunier and Thomas Scialom and Gabriel Synnaeve},
    year={2024},
    eprint={2308.12950},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://doi.org/10.48550/arXiv.2308.12950},
    doi={10.48550/arXiv.2308.12950}
}

%% Llama paper
@misc{touvron2023llama,
    title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
    author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
    year={2023},
    eprint={2307.09288},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://doi.org/10.48550/arXiv.2307.09288},
    doi={10.48550/arXiv.2307.09288}
}

# OpenAI Scaling laws
@misc{kaplan2020scaling,
    title={Scaling Laws for Neural Language Models}, 
    author={Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
    year={2020},
    eprint={2001.08361},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://doi.org/10.48550/arXiv.2001.08361},
    doi={10.48550/arXiv.2001.08361}
}

# Bloom paper
@misc{workshop2023bloom,
    title={BLOOM: A 176B-Parameter Open-Access Multilingual Language Model}, 
    author={BigScience Workshop and : and Teven Le Scao and Angela Fan and Christopher Akiki and Ellie Pavlick and Suzana Ilić and Daniel Hesslow and Roman Castagné and Alexandra Sasha Luccioni and François Yvon and Matthias Gallé and Jonathan Tow and Alexander M. Rush and Stella Biderman and Albert Webson and Pawan Sasanka Ammanamanchi and Thomas Wang and Benoît Sagot and Niklas Muennighoff and Albert Villanova del Moral and Olatunji Ruwase and Rachel Bawden and Stas Bekman and Angelina McMillan-Major and Iz Beltagy and Huu Nguyen and Lucile Saulnier and Samson Tan and Pedro Ortiz Suarez and Victor Sanh and Hugo Laurençon and Yacine Jernite and Julien Launay and Margaret Mitchell and Colin Raffel and Aaron Gokaslan and Adi Simhi and Aitor Soroa and Alham Fikri Aji and Amit Alfassy and Anna Rogers and Ariel Kreisberg Nitzav and Canwen Xu and Chenghao Mou and Chris Emezue and Christopher Klamm and Colin Leong and Daniel van Strien and David Ifeoluwa Adelani and Dragomir Radev and Eduardo González Ponferrada and Efrat Levkovizh and Ethan Kim and Eyal Bar Natan and Francesco De Toni and Gérard Dupont and Germán Kruszewski and Giada Pistilli and Hady Elsahar and Hamza Benyamina and Hieu Tran and Ian Yu and Idris Abdulmumin and Isaac Johnson and Itziar Gonzalez-Dios and Javier de la Rosa and Jenny Chim and Jesse Dodge and Jian Zhu and Jonathan Chang and Jörg Frohberg and Joseph Tobing and Joydeep Bhattacharjee and Khalid Almubarak and Kimbo Chen and Kyle Lo and Leandro Von Werra and Leon Weber and Long Phan and Loubna Ben allal and Ludovic Tanguy and Manan Dey and Manuel Romero Muñoz and Maraim Masoud and María Grandury and Mario Šaško and Max Huang and Maximin Coavoux and Mayank Singh and Mike Tian-Jian Jiang and Minh Chien Vu and Mohammad A. Jauhar and Mustafa Ghaleb and Nishant Subramani and Nora Kassner and Nurulaqilla Khamis and Olivier Nguyen and Omar Espejel and Ona de Gibert and Paulo Villegas and Peter Henderson and Pierre Colombo and Priscilla Amuok and Quentin Lhoest and Rheza Harliman and Rishi Bommasani and Roberto Luis López and Rui Ribeiro and Salomey Osei and Sampo Pyysalo and Sebastian Nagel and Shamik Bose and Shamsuddeen Hassan Muhammad and Shanya Sharma and Shayne Longpre and Somaieh Nikpoor and Stanislav Silberberg and Suhas Pai and Sydney Zink and Tiago Timponi Torrent and Timo Schick and Tristan Thrush and Valentin Danchev and Vassilina Nikoulina and Veronika Laippala and Violette Lepercq and Vrinda Prabhu and Zaid Alyafeai and Zeerak Talat and Arun Raja and Benjamin Heinzerling and Chenglei Si and Davut Emre Taşar and Elizabeth Salesky and Sabrina J. Mielke and Wilson Y. Lee and Abheesht Sharma and Andrea Santilli and Antoine Chaffin and Arnaud Stiegler and Debajyoti Datta and Eliza Szczechla and Gunjan Chhablani and Han Wang and Harshit Pandey and Hendrik Strobelt and Jason Alan Fries and Jos Rozen and Leo Gao and Lintang Sutawika and M Saiful Bari and Maged S. Al-shaibani and Matteo Manica and Nihal Nayak and Ryan Teehan and Samuel Albanie and Sheng Shen and Srulik Ben-David and Stephen H. Bach and Taewoon Kim and Tali Bers and Thibault Fevry and Trishala Neeraj and Urmish Thakker and Vikas Raunak and Xiangru Tang and Zheng-Xin Yong and Zhiqing Sun and Shaked Brody and Yallow Uri and Hadar Tojarieh and Adam Roberts and Hyung Won Chung and Jaesung Tae and Jason Phang and Ofir Press and Conglong Li and Deepak Narayanan and Hatim Bourfoune and Jared Casper and Jeff Rasley and Max Ryabinin and Mayank Mishra and Minjia Zhang and Mohammad Shoeybi and Myriam Peyrounette and Nicolas Patry and Nouamane Tazi and Omar Sanseviero and Patrick von Platen and Pierre Cornette and Pierre François Lavallée and Rémi Lacroix and Samyam Rajbhandari and Sanchit Gandhi and Shaden Smith and Stéphane Requena and Suraj Patil and Tim Dettmers and Ahmed Baruwa and Amanpreet Singh and Anastasia Cheveleva and Anne-Laure Ligozat and Arjun Subramonian and Aurélie Névéol and Charles Lovering and Dan Garrette and Deepak Tunuguntla and Ehud Reiter and Ekaterina Taktasheva and Ekaterina Voloshina and Eli Bogdanov and Genta Indra Winata and Hailey Schoelkopf and Jan-Christoph Kalo and Jekaterina Novikova and Jessica Zosa Forde and Jordan Clive and Jungo Kasai and Ken Kawamura and Liam Hazan and Marine Carpuat and Miruna Clinciu and Najoung Kim and Newton Cheng and Oleg Serikov and Omer Antverg and Oskar van der Wal and Rui Zhang and Ruochen Zhang and Sebastian Gehrmann and Shachar Mirkin and Shani Pais and Tatiana Shavrina and Thomas Scialom and Tian Yun and Tomasz Limisiewicz and Verena Rieser and Vitaly Protasov and Vladislav Mikhailov and Yada Pruksachatkun and Yonatan Belinkov and Zachary Bamberger and Zdeněk Kasner and Alice Rueda and Amanda Pestana and Amir Feizpour and Ammar Khan and Amy Faranak and Ana Santos and Anthony Hevia and Antigona Unldreaj and Arash Aghagol and Arezoo Abdollahi and Aycha Tammour and Azadeh HajiHosseini and Bahareh Behroozi and Benjamin Ajibade and Bharat Saxena and Carlos Muñoz Ferrandis and Daniel McDuff and Danish Contractor and David Lansky and Davis David and Douwe Kiela and Duong A. Nguyen and Edward Tan and Emi Baylor and Ezinwanne Ozoani and Fatima Mirza and Frankline Ononiwu and Habib Rezanejad and Hessie Jones and Indrani Bhattacharya and Irene Solaiman and Irina Sedenko and Isar Nejadgholi and Jesse Passmore and Josh Seltzer and Julio Bonis Sanz and Livia Dutra and Mairon Samagaio and Maraim Elbadri and Margot Mieskes and Marissa Gerchick and Martha Akinlolu and Michael McKenna and Mike Qiu and Muhammed Ghauri and Mykola Burynok and Nafis Abrar and Nazneen Rajani and Nour Elkott and Nour Fahmy and Olanrewaju Samuel and Ran An and Rasmus Kromann and Ryan Hao and Samira Alizadeh and Sarmad Shubber and Silas Wang and Sourav Roy and Sylvain Viguier and Thanh Le and Tobi Oyebade and Trieu Le and Yoyo Yang and Zach Nguyen and Abhinav Ramesh Kashyap and Alfredo Palasciano and Alison Callahan and Anima Shukla and Antonio Miranda-Escalada and Ayush Singh and Benjamin Beilharz and Bo Wang and Caio Brito and Chenxi Zhou and Chirag Jain and Chuxin Xu and Clémentine Fourrier and Daniel León Periñán and Daniel Molano and Dian Yu and Enrique Manjavacas and Fabio Barth and Florian Fuhrimann and Gabriel Altay and Giyaseddin Bayrak and Gully Burns and Helena U. Vrabec and Imane Bello and Ishani Dash and Jihyun Kang and John Giorgi and Jonas Golde and Jose David Posada and Karthik Rangasai Sivaraman and Lokesh Bulchandani and Lu Liu and Luisa Shinzato and Madeleine Hahn de Bykhovetz and Maiko Takeuchi and Marc Pàmies and Maria A Castillo and Marianna Nezhurina and Mario Sänger and Matthias Samwald and Michael Cullan and Michael Weinberg and Michiel De Wolf and Mina Mihaljcic and Minna Liu and Moritz Freidank and Myungsun Kang and Natasha Seelam and Nathan Dahlberg and Nicholas Michio Broad and Nikolaus Muellner and Pascale Fung and Patrick Haller and Ramya Chandrasekhar and Renata Eisenberg and Robert Martin and Rodrigo Canalli and Rosaline Su and Ruisi Su and Samuel Cahyawijaya and Samuele Garda and Shlok S Deshmukh and Shubhanshu Mishra and Sid Kiblawi and Simon Ott and Sinee Sang-aroonsiri and Srishti Kumar and Stefan Schweter and Sushil Bharati and Tanmay Laud and Théo Gigant and Tomoya Kainuma and Wojciech Kusa and Yanis Labrak and Yash Shailesh Bajaj and Yash Venkatraman and Yifan Xu and Yingxin Xu and Yu Xu and Zhe Tan and Zhongli Xie and Zifan Ye and Mathilde Bras and Younes Belkada and Thomas Wolf},
    year={2023},
    eprint={2211.05100},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://doi.org/10.48550/arXiv.2211.05100},
    doi={10.48550/arXiv.2211.05100}
}

@misc{almazrouei2023falcon,
    title={The Falcon Series of Open Language Models}, 
    author={Ebtesam Almazrouei and Hamza Alobeidli and Abdulaziz Alshamsi and Alessandro Cappelli and Ruxandra Cojocaru and Mérouane Debbah and Étienne Goffinet and Daniel Hesslow and Julien Launay and Quentin Malartic and Daniele Mazzotta and Badreddine Noune and Baptiste Pannier and Guilherme Penedo},
    year={2023},
    eprint={2311.16867},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://doi.org/10.48550/arXiv.2311.16867},
    doi={10.48550/arXiv.2311.16867}
}


@misc{takase2023b2t,
    title={On Layer Normalizations and Residual Connections in Transformers}, 
    author={Sho Takase and Shun Kiyono and Sosuke Kobayashi and Jun Suzuki},
    year={2023},
    eprint={2206.00330},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

# CodeBLEU
@misc{ren2020codebleu,
    title={CodeBLEU: a Method for Automatic Evaluation of Code Synthesis}, 
    author={Shuo Ren and Daya Guo and Shuai Lu and Long Zhou and Shujie Liu and Duyu Tang and Neel Sundaresan and Ming Zhou and Ambrosio Blanco and Shuai Ma},
    year={2020},
    eprint={2009.10297},
    archivePrefix={arXiv},
    primaryClass={cs.SE},
    url={https://doi.org/10.48550/arXiv.2009.10297},
    doi={10.48550/arXiv.2009.10297}
}


@misc{li2023starcoder,
    title={StarCoder: may the source be with you!}, 
    author={Raymond Li and Loubna Ben Allal and Yangtian Zi and Niklas Muennighoff and Denis Kocetkov and Chenghao Mou and Marc Marone and Christopher Akiki and Jia Li and Jenny Chim and Qian Liu and Evgenii Zheltonozhskii and Terry Yue Zhuo and Thomas Wang and Olivier Dehaene and Mishig Davaadorj and Joel Lamy-Poirier and João Monteiro and Oleh Shliazhko and Nicolas Gontier and Nicholas Meade and Armel Zebaze and Ming-Ho Yee and Logesh Kumar Umapathi and Jian Zhu and Benjamin Lipkin and Muhtasham Oblokulov and Zhiruo Wang and Rudra Murthy and Jason Stillerman and Siva Sankalp Patel and Dmitry Abulkhanov and Marco Zocca and Manan Dey and Zhihan Zhang and Nour Fahmy and Urvashi Bhattacharyya and Wenhao Yu and Swayam Singh and Sasha Luccioni and Paulo Villegas and Maxim Kunakov and Fedor Zhdanov and Manuel Romero and Tony Lee and Nadav Timor and Jennifer Ding and Claire Schlesinger and Hailey Schoelkopf and Jan Ebert and Tri Dao and Mayank Mishra and Alex Gu and Jennifer Robinson and Carolyn Jane Anderson and Brendan Dolan-Gavitt and Danish Contractor and Siva Reddy and Daniel Fried and Dzmitry Bahdanau and Yacine Jernite and Carlos Muñoz Ferrandis and Sean Hughes and Thomas Wolf and Arjun Guha and Leandro von Werra and Harm de Vries},
    year={2023},
    eprint={2305.06161},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://doi.org/10.48550/arXiv.2305.06161},
    doi={10.48550/arXiv.2305.06161}
}

@misc{codellama-i7btemplate,
    title = {TheBloke/CodeLlama-7B-Instruct-GGUF},
    url={https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF#prompt-template-codellama}
}

@webpage{gtp4leaked,
    author = {Maximilian Schreiner},
    title = {GPT-4 architecture, datasets, costs and more leaked},
    howpublished = {online},
    publisher = {THE DECODER},
    year = {2020}, 
    url={https://the-decoder.com/gpt-4-architecture-datasets-costs-and-more-leaked/},
    cited={03.08.2024}
}


@misc{raffel2023exploring,
    title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer}, 
    author={Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
    year={2023},
    eprint={1910.10683},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://doi.org/10.48550/arXiv.1910.10683},
    doi={10.48550/arXiv.1910.10683}
}


@misc{lewis2019bart,
    title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension}, 
    author={Mike Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and Abdelrahman Mohamed and Omer Levy and Ves Stoyanov and Luke Zettlemoyer},
    year={2019},
    eprint={1910.13461},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://doi.org/10.48550/arXiv.1910.13461},
    doi={10.48550/arXiv.1910.13461}
}

@misc{liu2018generating,
    title={Generating Wikipedia by Summarizing Long Sequences}, 
    author={Peter J. Liu and Mohammad Saleh and Etienne Pot and Ben Goodrich and Ryan Sepassi and Lukasz Kaiser and Noam Shazeer},
    year={2018},
    eprint={1801.10198},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://doi.org/10.48550/arXiv.1801.10198},
    doi={10.48550/arXiv.1801.10198}
}

@misc{radford2018improving,
    title={Improving Language Understanding by Generative Pre-Training}, 
    author={Alec Radford and Karthik Narasimhan and Tim Salimans and Ilya Sutskever},
    year={2018},
    cited ={2024-08-03}
}


@misc{gptarchitecture,
    author={Marxav},
    title={Full GPT architecture.png},
    url={https://commons.wikimedia.org/wiki/File:Full_GPT_architecture.png},
    cited={2024-08-03},
    year={2022}
}

@inproceedings{papinenibleu2002,
    title = "Bleu: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    editor = "Isabelle, Pierre  and
      Charniak, Eugene  and
      Lin, Dekang",
    booktitle = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2002",
    address = "Philadelphia, Pennsylvania, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P02-1040",
    doi = "10.3115/1073083.1073135",
    pages = "311--318",
}

# OutOfTheBLEU
@misc{evtikhiev2020out,
    title={Out of the BLEU: how should we assess quality of the Code Generation models?}, 
    author={Mikhail Evtikhiev and Egor Bogomolov and Yaroslav Sokolov and Timofey Bryksin},
    year={2022},
    eprint={2208.03133},
    archivePrefix={arXiv},
    primaryClass={cs.SE},
    url={https://doi.org/10.48550/arXiv.2208.03133},
    doi={10.48550/arXiv.2208.03133}
}

@misc{zheng2023codegeex,
      title={CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X}, 
      author={Qinkai Zheng and Xiao Xia and Xu Zou and Yuxiao Dong and Shan Wang and Yufei Xue and Zihan Wang and Lei Shen and Andi Wang and Yang Li and Teng Su and Zhilin Yang and Jie Tang},
      year={2023},
      eprint={2303.17568},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{Allal2023,
    author = {Loubna Ben Allal},
    title = {santacoder-finetuning},
    year = {2023},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {online},
    url={https://github.com/loubnabnl/santacoder-finetuning},
    commit = {13b6933}
}

# ROUGE
@inproceedings{lin2004rouge,
    title = "ROUGE: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-1013",
    pages = "74--81",
}

# chrF
@inproceedings{popovic2015chrf,
    title = "chr{F}: character n-gram {F}-score for automatic {MT} evaluation",
    author = "Popovi{\'c}, Maja",
    editor = "Bojar, Ond{\v{r}}ej  and
      Chatterjee, Rajan  and
      Federmann, Christian  and
      Haddow, Barry  and
      Hokamp, Chris  and
      Huck, Matthias  and
      Logacheva, Varvara  and
      Pecina, Pavel",
    booktitle = "Proceedings of the Tenth Workshop on Statistical Machine Translation",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W15-3049",
    doi = "10.18653/v1/W15-3049",
    pages = "392--395",
}

# chrF++
@inproceedings{popovic2017chrf,
    title = "chr{F}++: words helping character n-grams",
    author = "Popovi{\'c}, Maja",
    editor = "Bojar, Ond{\v{r}}ej  and
      Buck, Christian  and
      Chatterjee, Rajen  and
      Federmann, Christian  and
      Graham, Yvette  and
      Haddow, Barry  and
      Huck, Matthias  and
      Yepes, Antonio Jimeno  and
      Koehn, Philipp  and
      Kreutzer, Julia",
    booktitle = "Proceedings of the Second Conference on Machine Translation",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W17-4770",
    doi = "10.18653/v1/W17-4770",
    pages = "612--618",
}

@webpage{neutelings,
    author =       "Izaak Neutelings",
    title =        "Neural networks",
    language=       "en-US",
    howpublished = "online",
    publisher =    "TikZ.net",
    url =          "https://tikz.net/neural_networks/",
    revised = "2024-12-04",
    year="2021"
}



@ARTICLE{9590539,
    author={Zhou, Yu and Cui, Suxia and Wang, Yonghui},
    journal={IEEE Access}, 
    title={Machine Learning Based Embedded Code Multi-Label Classification}, 
    year={2021},
    volume={9},
    pages={150187-150200},
    doi={10.1109/ACCESS.2021.3123498}
}

@misc{shazeer2019fast,
      title={Fast Transformer Decoding: One Write-Head is All You Need}, 
      author={Noam Shazeer},
      year={2019},
      eprint={1911.02150},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
    url={https://doi.org/10.48550/arXiv.1911.02150},
    doi={10.48550/arXiv.1911.02150}
}


@inproceedings{post-2018-call,
    title = "A Call for Clarity in Reporting {BLEU} Scores",
    author = "Post, Matt",
    editor = "Bojar, Ond{\v{r}}ej  and
      Chatterjee, Rajen  and
      Federmann, Christian  and
      Fishel, Mark  and
      Graham, Yvette  and
      Haddow, Barry  and
      Huck, Matthias  and
      Yepes, Antonio Jimeno  and
      Koehn, Philipp  and
      Monz, Christof  and
      Negri, Matteo  and
      N{\'e}v{\'e}ol, Aur{\'e}lie  and
      Neves, Mariana  and
      Post, Matt  and
      Specia, Lucia  and
      Turchi, Marco  and
      Verspoor, Karin",
    booktitle = "Proceedings of the Third Conference on Machine Translation: Research Papers",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W18-6319",
    doi = "10.18653/v1/W18-6319",
    pages = "186--191",
}

@misc{grrouge,
    author = {Google Research},
    title = {google-research/rouge},
    cited = {2024-04-18},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {online},
    url={https://github.com/google-research/google-research/tree/master/rouge},
    commit = {1d49f2c}
}

@misc{codebleugh,
    author = {Konstantin Chernyshev},
    title = {codebleu},
    year={2023},
    cited = {2024-04-18},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {online},
    url={https://github.com/k4black/codebleu},
    commit = {c766a77}
}

@webpage{githubcopilot,
    author =       "Shuyin Zhao",
    title =        "GitHub Copilot now has a better AI model and new capabilities",
    language=       "en-US",
    howpublished = "online",
    publisher =    "The GitHub Blog",
    day="14",
    month="02",
    year= "2023",
    url = "https://github.blog/2023-02-14-github-copilot-now-has-a-better-ai-model-and-new-capabilities/",
    cited =        "2024-19-04"
}

@misc{devlin2019bert,
    title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
    author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
    year={2019},
    eprint={1810.04805},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    doi={10.48550/arXiv.1810.0480},
    url={https://doi.org/10.48550/arXiv.1810.0480}
}

@misc{yang2020xlnet,
    title={XLNet: Generalized Autoregressive Pretraining for Language Understanding}, 
    author={Zhilin Yang and Zihang Dai and Yiming Yang and Jaime Carbonell and Ruslan Salakhutdinov and Quoc V. Le},
    year={2020},
    eprint={1906.08237},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    doi={10.48550/arXiv.1906.08237},
    url={https://doi.org/10.48550/arXiv.1906.08237}
}

@misc{fedus2018maskgan,
      title={MaskGAN: Better Text Generation via Filling in the\_\_\_\_\_\_}, 
      author={William Fedus and Ian Goodfellow and Andrew M. Dai},
      year={2018},
      eprint={1801.07736},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
doi={10.48550/arXiv.1801.07736},
url={https://doi.org/10.48550/arXiv.1801.07736}
}

@misc{ainslie2023gqa,
      title={GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints}, 
      author={Joshua Ainslie and James Lee-Thorp and Michiel de Jong and Yury Zemlyanskiy and Federico Lebrón and Sumit Sanghai},
      year={2023},
      eprint={2305.13245},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
url={
https://doi.org/10.48550/arXiv.2305.13245},
doi={10.48550/arXiv.2305.13245}
}

@misc{deepseekai2024deepseek,
    title={DeepSeek LLM: Scaling Open-Source Language Models with Longtermism}, 
    author={DeepSeek-AI and : and Xiao Bi and Deli Chen and Guanting Chen and Shanhuang Chen and Damai Dai and Chengqi Deng and Honghui Ding and Kai Dong and Qiushi Du and Zhe Fu and Huazuo Gao and Kaige Gao and Wenjun Gao and Ruiqi Ge and Kang Guan and Daya Guo and Jianzhong Guo and Guangbo Hao and Zhewen Hao and Ying He and Wenjie Hu and Panpan Huang and Erhang Li and Guowei Li and Jiashi Li and Yao Li and Y. K. Li and Wenfeng Liang and Fangyun Lin and A. X. Liu and Bo Liu and Wen Liu and Xiaodong Liu and Xin Liu and Yiyuan Liu and Haoyu Lu and Shanghao Lu and Fuli Luo and Shirong Ma and Xiaotao Nie and Tian Pei and Yishi Piao and Junjie Qiu and Hui Qu and Tongzheng Ren and Zehui Ren and Chong Ruan and Zhangli Sha and Zhihong Shao and Junxiao Song and Xuecheng Su and Jingxiang Sun and Yaofeng Sun and Minghui Tang and Bingxuan Wang and Peiyi Wang and Shiyu Wang and Yaohui Wang and Yongji Wang and Tong Wu and Y. Wu and Xin Xie and Zhenda Xie and Ziwei Xie and Yiliang Xiong and Hanwei Xu and R. X. Xu and Yanhong Xu and Dejian Yang and Yuxiang You and Shuiping Yu and Xingkai Yu and B. Zhang and Haowei Zhang and Lecong Zhang and Liyue Zhang and Mingchuan Zhang and Minghua Zhang and Wentao Zhang and Yichao Zhang and Chenggang Zhao and Yao Zhao and Shangyan Zhou and Shunfeng Zhou and Qihao Zhu and Yuheng Zou},
    year={2024},
    eprint={2401.02954},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    doi={10.48550/arXiv.2401.02954},
    url={https://doi.org/10.48550/arXiv.2401.02954}
}

@misc{guo2024deepseekcoder,
    title={DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence}, 
    author={Daya Guo and Qihao Zhu and Dejian Yang and Zhenda Xie and Kai Dong and Wentao Zhang and Guanting Chen and Xiao Bi and Y. Wu and Y. K. Li and Fuli Luo and Yingfei Xiong and Wenfeng Liang},
    year={2024},
    eprint={2401.14196},
    archivePrefix={arXiv},
    primaryClass={cs.SE},
    url={https://doi.org/10.48550/arXiv.2401.14196},
    doi={10.48550/arXiv.2401.14196}
}

@misc{dettmers2023qlora,
      title={QLoRA: Efficient Finetuning of Quantized LLMs}, 
      author={Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
      year={2023},
      eprint={2305.14314},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
    doi={10.48550/arXiv.2305.14314},
    url={https://doi.org/10.48550/arXiv.2305.14314}
}

@article{lacoste2019quantifying,
  title={Quantifying the Carbon Emissions of Machine Learning},
  author={Lacoste, Alexandre and Luccioni, Alexandra and Schmidt, Victor and Dandres, Thomas},
  journal={arXiv preprint arXiv:1910.09700},
  year={2019}
}

  @misc{enwiki:1221184532,
    author = "{Wikipedia contributors}",
    title = "Universal approximation theorem --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2024",
    url = "https://en.wikipedia.org/w/index.php?title=Universal_approximation_theorem&oldid=1221184532",
    note = "[Online; prístup 5-máj-2024]"
  }

@misc{kulal2019spoc,
      title={SPoC: Search-based Pseudocode to Code}, 
      author={Sumith Kulal and Panupong Pasupat and Kartik Chandra and Mina Lee and Oded Padon and Alex Aiken and Percy Liang},
      year={2019},
      eprint={1906.04908},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
    doi={10.48550/arXiv.1906.04908},
url={https://doi.org/10.48550/arXiv.1906.04908}
}

@webpage{llamaquant,
    author = {Johannes Gäßler},
    title = {Perplexity},
    howpublished = {online},
    publisher = {GitHub},
    year = {2024}, 
    url={https://github.com/ggerganov/llama.cpp/tree/master/examples/perplexity},
    cited={01.05.2024}
}

@misc{EEAGlossary2023,
  title={Glossary: Carbon dioxide equivalent},
  author={European Environment Agency},
  year={2023},
  month={August},
  note={Založené na: IPCC Third Assessment Report, 2001},
    howpublished={online},
  url={https://ec.europa.eu/eurostat/statistics-explained/index.php?title=Glossary:Carbon_dioxide_equivalent},
  organization={European Environment Agency},
  journal={Statistics Explained},
  cited={03.05.2024}
}

@misc{enwiki:1222140497,
    author = "{Wikipedia contributors}",
    title = "Perceptron --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2024",
    url = "https://en.wikipedia.org/w/index.php?title=Perceptron&oldid=1222140497",
    note = "[Online; accessed 2-May-2024]"
}

@misc{enwiki:1222136552,
    author = "{Wikipedia contributors}",
    title = "Deep learning --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2024",
    url = "https://en.wikipedia.org/w/index.php?title=Deep_learning&oldid=1222136552",
    note = "[Online; accessed 2-May-2024]"
}