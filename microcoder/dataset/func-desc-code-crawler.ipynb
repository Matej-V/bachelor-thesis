{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract C/C++ source codes from GitHub repositories\n",
    "\n",
    "This python notebook was used to gather C/C++ source codes from GitHub repositories, extract functions together with their descriptions, and save them in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from github import Github\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "import regex as re\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the repositories according to criteria\n",
    "\n",
    "We chose the repositories according to the following criteria:\n",
    "- Topic: we chose topics [\"microcontroller\", \"firmware\", \"embedded-systems\"]\n",
    "- Keywords: [\"Cortex-M0\", \"Cortex-M3\", \"Cortex-M4\", \"Cortex-A\", \"STM32\", \"ESP32\", \"ESP8266\", \"ATmega328\", \"PIC16F877A\"]\n",
    "- Language: we chose the language \"C++\" or \"C\"\n",
    "- Number of stars: we chose repositories in descending order of stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These repositories are skipped\n",
    "skip_repos = [\"msdk\",'renode', 'u8g2', 'GuiLite']\n",
    "\n",
    "# Create the Github object\n",
    "g = Github(os.environ['GITHUB_TOKEN'])\n",
    "\n",
    "# Create the folder to save the repositories\n",
    "if not os.path.exists('finalRepos'):\n",
    "    os.makedirs('finalRepos')\n",
    "\n",
    "# Create the folder to save the index .json files - information about the downloaded repositories\n",
    "if not os.path.exists('finalRepos/index'):\n",
    "    os.makedirs('finalRepos/index')\n",
    "\n",
    "\n",
    "def clone_repository(repo, parent_folder: str):\n",
    "    '''\n",
    "    Clone the repository, remove the .git folder, remove all files except C/C++ files and remove empty directories\n",
    "\n",
    "    Args:\n",
    "        repo: Repository object\n",
    "        parent_folder: Folder to save the repository\n",
    "    '''\n",
    "    # Clone the whole repository\n",
    "    os.system(f'git clone --depth=1 --filter=blob:none {repo.clone_url} {parent_folder}/{repo.name}')\n",
    "\n",
    "    # Change directory to the repository\n",
    "    os.chdir(f'{parent_folder}/{repo.name}')\n",
    "\n",
    "    # Remove the .git folder\n",
    "    os.system(\"rm -rf .git\")\n",
    "\n",
    "    # Remove all files from the repository except C/C++ files\n",
    "    os.system(\"find . -type f ! -name '*.c' ! -name '*.cpp' -delete\")\n",
    "\n",
    "    # Remove empty directories\n",
    "    os.system(\"find . -type d -empty -delete\")\n",
    "\n",
    "    # Change directory back to parent\n",
    "    os.chdir('../..')\n",
    "\n",
    "def process_query(query: str, n: int, folder_to_save: str, keywords: List[str]):\n",
    "    '''\n",
    "    Process the query and download the repositories\n",
    "\n",
    "    Args:\n",
    "        query: Query to search the repositories\n",
    "        n: maximum number of repositories to download\n",
    "        folder_to_save: Folder to save the repositories\n",
    "        keywords: List of keywords to search\n",
    "    '''\n",
    "    for keyword in keywords:\n",
    "        i = 0 # Number of downloaded repositories\n",
    "        for repo in g.search_repositories(query=query(keyword), sort=\"stars\", order=\"desc\"):\n",
    "            if i == n: # Check if we have downloaded n repositories\n",
    "                break\n",
    "            else:\n",
    "                if repo.name in skip_repos:\n",
    "                    continue\n",
    "                if os.path.exists(f'{folder_to_save}/{repo.name}'):\n",
    "                    print(f\"Skipping {repo.name} as it is already downloaded\")\n",
    "                    continue\n",
    "                else:\n",
    "                    clone_repository(repo, folder_to_save)\n",
    "                    i += 1\n",
    "                \n",
    "                # Add file with information about the repository\n",
    "                license = repo.license.name if repo.license else \"None\"\n",
    "                with open(f'{folder_to_save}/index/{repo.name}.json', 'w') as f:\n",
    "                    f.write(f'{{\"name\": \"{repo.name}\", \"url\": \"{repo.html_url}\", \"license\": \"{license}\", \"key\": \"{keyword}\", \"stars\": {repo.stargazers_count}, \"user\": \"{repo.owner.login}\", \"time_downloaded\": \"{time.strftime(\"%Y-%m-%d %H:%M:%S\")}\"}}')\n",
    "                    \n",
    "    print(f\"Downloaded {i} repositories for {keyword}\")\n",
    "\n",
    "# Process each topic\n",
    "process_query(lambda x: f\"topic:{x} NOT graphics NOT opengl NOT directx NOT WebGL NOT GUI language:C language:C++\", 50, 'finalRepos', [\"microcontroller\", \"firmware\", \"embedded-systems\"])\n",
    "\n",
    "# Process each keyword\n",
    "process_query(lambda x: f\"{x} NOT graphics NOT opengl NOT directx NOT WebGL NOT GUI language:C language:C++\", 30, 'finalRepos', [\"Cortex-M0\", \"Cortex-M3\", \"Cortex-M4\", \"Cortex-A\", \"STM32\", \"ESP32\", \"ESP8266\", \"ATmega328\", \"PIC16F877A\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter folders\n",
    "\n",
    "Delete folders and files that contain keyword 'test' in their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete folders that have 'test' in their name as they may be less relevant\n",
    "os.system(\"find finalRepos -type d -name '*test*' -exec rm -rf {} +\")\n",
    "# Delete files that have 'test' in their name as they may be less relevant\n",
    "os.system(\"find finalRepos -type f -name '*test*' -exec rm -rf {} +\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit non doxygen comments so that doxygen can process them\n",
    "\n",
    "USed to rewrite comments from format /* ... */ to /**... */ so that doxygen can process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_decoded_files = 0\n",
    "not_found_files = 0\n",
    "\n",
    "# Rewrite multiline comments from format /* ... */ to /**... */, use regex\n",
    "for root, dirs, files in os.walk('finalRepos'):\n",
    "    for file in files:\n",
    "        if file.endswith('.c') or file.endswith('.cpp'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                    content = re.sub(r'\\/\\*\\n', '/**\\n', content, flags=re.DOTALL)\n",
    "                    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                        f.write(content)\n",
    "            except UnicodeDecodeError  as e:\n",
    "                print(f\"Error decoding file '{file_path}': {e}\")\n",
    "                wrong_decoded_files += 1\n",
    "                # remove the file\n",
    "                os.remove(file_path)\n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"File '{file_path}' not found: {e}\")\n",
    "                not_found_files += 1\n",
    "                # remove the file\n",
    "                os.remove(file_path)\n",
    "\n",
    "print(f\"Wrong decoded files: {wrong_decoded_files}\")\n",
    "print(f\"Not found files: {not_found_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract functions from source files\n",
    "\n",
    "This part of code is used to extract functions from source files. It uses doxygen to parse the source files and create an XML file. Then, it reads the XML file and extracts functions together with their descriptions. The extracted functions are periodically saved in .parquet format to prevent data loss in case of a crash and to save memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_files = int(subprocess.check_output(\"find finalRepos -name '*.c' -o -name '*.cpp' | wc -l\", shell=True))\n",
    "print(f\"Total files: {total_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_doxyfile(filename: str):\n",
    "    '''\n",
    "    Creates a Doxyfile for the specified file.\n",
    "\n",
    "    Parameters:\n",
    "        filename (str): Path to the file for which the Doxyfile will be created.\n",
    "    '''\n",
    "    with open('Doxyfile', 'w') as f:\n",
    "        f.write(f'''\n",
    "            DOXYFILE_ENCODING      = UTF-8\n",
    "            JAVADOC_BLOCK          = YES\n",
    "            PROJECT_NAME           = \"AutoGeneratedDoxyfile\"\n",
    "            OUTPUT_DIRECTORY       = DoxygenOutput\n",
    "            GENERATE_XML           = YES\n",
    "            GENERATE_HTML          = NO\n",
    "            GENERATE_LATEX         = NO\n",
    "            XML_OUTPUT             = xml_output\n",
    "            INPUT                  = {filename}\n",
    "        ''')\n",
    "\n",
    "def run_doxygen():\n",
    "    '''\n",
    "    Runs Doxygen with autogenerated Doxyfile\n",
    "    '''\n",
    "    try:\n",
    "        subprocess.run(['doxygen', 'Doxyfile'], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        # print(\"Doxygen executed successfully.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running Doxygen: {e}\")\n",
    "\n",
    "def parse_xml_and_extract_functions(xml_file: str) -> Dict:\n",
    "    '''\n",
    "    Parses the XML index file and extracts functions from it.\n",
    "\n",
    "    Parameters:\n",
    "        xml_file (str): Path to the XML index file.\n",
    "\n",
    "    Returns:\n",
    "        Dict: Dictionary containing extracted functions.\n",
    "    '''\n",
    "    # Parse the XML index file and extract file names\n",
    "    try:\n",
    "        tree = etree.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "    except etree.XMLSyntaxError as e:\n",
    "        print(f\"Error parsing XML file: {e}\")\n",
    "        return {}\n",
    "\n",
    "    # Function records for the current source file\n",
    "    functions_data = []\n",
    "\n",
    "    def get_description(element: etree.Element) -> Dict:\n",
    "        '''\n",
    "        Extracts the description of the function from the XML element.\n",
    "\n",
    "        Parameters:\n",
    "            element (etree.Element): XML element containing the function.\n",
    "        \n",
    "        Returns:\n",
    "            Dict: Dictionary containing the description of the function.\n",
    "        '''\n",
    "        description = { 'brief': None, 'detailed': None, 'return': None, 'parameters': [] }\n",
    "        for para in element.xpath('.//briefdescription/para'):\n",
    "            description['brief'] = para.text + '\\n' if para.text is not None else None\n",
    "        for para in element.xpath('.//detaileddescription/para'):\n",
    "            if para.text is not None:\n",
    "                description['detailed'] = para.text + '\\n'\n",
    "            else:\n",
    "                for item in para.iterchildren():\n",
    "                    if item.tag == 'simplesect' and item.get('kind') == 'return':\n",
    "                        description['return'] = item.find('para').text + '\\n' if item.find('para') is not None and item.find('para').text is not None else None\n",
    "                    elif item.tag == 'parameterlist':\n",
    "                        for parameter_item in item.iter('parameteritem'):\n",
    "                            kind = item.get('kind')\n",
    "                            name = parameter_item.find(\"parameternamelist/parametername\").text if parameter_item.find(\"parameternamelist/parametername\") is not None and parameter_item.find(\"parameternamelist/parametername\").text is not None else None\n",
    "                            param_desc = parameter_item.find(\"parameterdescription/para\").text if parameter_item.find(\"parameterdescription/para\") is not None and parameter_item.find(\"parameterdescription/para\").text is not None else None\n",
    "                            description['parameters'].append({'kind': kind, 'name': name, 'description': param_desc})\n",
    "        return description\n",
    "\n",
    "\n",
    "    for compound in root.xpath('//compound[@kind=\"file\"]'):\n",
    "        try:\n",
    "            c_file_tree = etree.parse(os.path.join('./DoxygenOutput/xml_output/', f\"{compound.get('refid')}.xml\"))\n",
    "            c_file_root = c_file_tree.getroot()\n",
    "        except etree.XMLSyntaxError as e:\n",
    "            print(f\"Error parsing XML file: {e}\")\n",
    "            continue\n",
    "\n",
    "        for member in c_file_root.xpath('//memberdef[@kind=\"function\"]'):\n",
    "            try:\n",
    "                record = {'language': c_file_root.find('.//compounddef').get('language')}\n",
    "\n",
    "                if member.find('.//briefdescription/para') is None and member.find('.//detaileddescription/para') is None:\n",
    "                    continue\n",
    "\n",
    "                # Add the file name to the record, remove finalRepos/ from the path\n",
    "                record['file'] = '/'.join(member.find('.//location').get('file').split('/')[1:])\n",
    "\n",
    "                record['description'] = get_description(member)\n",
    "\n",
    "                record['name'] = member.find('.//name').text\n",
    "                record['signature'] = member.find('.//definition').text + member.find('.//argsstring').text\n",
    "\n",
    "                source_file_location = member.find('.//location').get('file')\n",
    "\n",
    "                if member.find('.//location').get('bodystart') is None or member.find('.//location').get('bodyend') is None:\n",
    "                    # Probably 1-liner function - skip\n",
    "                    continue\n",
    "\n",
    "                body_start = int(member.find('.//location').get('bodystart'))\n",
    "                body_end = int(member.find('.//location').get('bodyend'))\n",
    "                with open(source_file_location, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                    record['code'] = ''.join(lines[body_start:body_end + 1])    \n",
    "                \n",
    "                functions_data.append(record)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing function in file {compound.get('refid')}.xml: {e}\")\n",
    "    return functions_data\n",
    "\n",
    "\n",
    "def run_function_extraction(folder_paths: List[str], save_path: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Extracts functions from all C/C++ files in the specified folder and saves them to a parquet file.\n",
    "\n",
    "    The function creates .parquet files for every 20000 files processed to save memory.\n",
    "\n",
    "    Parameters:\n",
    "        folder_paths (List[str]): List of paths to the folders containing C/C++ files.\n",
    "        save_path (str): Path to the parquet file where the extracted functions will be saved.\n",
    "    '''\n",
    "\n",
    "    extracted_functions_dataset = []    # List of dictionary records containing information about a function\n",
    "\n",
    "    \n",
    "    n_file = 0  # Processed files counter\n",
    "\n",
    "    # Iterate over all specified folders\n",
    "    for folder_path in folder_paths:\n",
    "        for root, dirs, files in os.walk(folder_path):            \n",
    "            for file in files:\n",
    "                if file.endswith('.c') or file.endswith('.cpp'):\n",
    "\n",
    "                    # Checkpoint - Save the extracted functions to a parquet file\n",
    "                    if n_file % 20000 == 0 and n_file != 0:\n",
    "                        print(f\"File number {n_file} out of {total_files}\")\n",
    "\n",
    "                        # Save the dataframe to a file and clear list to save memory\n",
    "                        pd.DataFrame(extracted_functions_dataset).to_parquet(f'{save_path}_{n_file}.parquet', index=False)\n",
    "\n",
    "                        # Clear the list to save memory\n",
    "                        extracted_functions_dataset = []\n",
    "\n",
    "                    file_path = os.path.join(root, file)\n",
    "\n",
    "                    # Create a Doxyfile for the file\n",
    "                    create_doxyfile(file_path)\n",
    "\n",
    "                    # Run Doxygen with the generated Doxyfile\n",
    "                    run_doxygen()\n",
    "\n",
    "                    # Parse the XML index file and extract file names\n",
    "                    extracted_functions_dataset += parse_xml_and_extract_functions('./DoxygenOutput/xml_output/index.xml')\n",
    "                    n_file += 1\n",
    "                \n",
    "    pd.DataFrame(extracted_functions_dataset).to_parquet(f'{save_path}_{n_file}.parquet', index=False)\n",
    "\n",
    "run_function_extraction(['finalRepos'], 'big_dataset_extraction')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
